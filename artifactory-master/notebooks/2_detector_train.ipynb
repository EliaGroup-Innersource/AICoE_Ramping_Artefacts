{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2   \n",
    "\n",
    "import sys\n",
    "sys.path.append('../artifactory/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "from artifact import Saw\n",
    "from data import ArtifactDataset, CachedArtifactDataset\n",
    "from detector import WindowTransformerDetector\n",
    "from utilities import parameters_k\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from azureml.core import ScriptRunConfig, Workspace, Experiment, Environment\n",
    "\n",
    "# stop warnings\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.54.0\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code LEFBX4ACQ to authenticate.\n",
      "The following tenants don't contain accessible subscriptions. Use 'az login --allow-no-subscriptions' to have tenant level access.\n",
      "20d9a90b-518d-4726-8ece-bb30a12e0f7a 'ELIA GROUP'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m3-mlops-mlw-dev\n",
      "m3-mlops-dev\n",
      "westeurope\n",
      "8de3e85d-b97f-48c1-a25b-5bddf9dc484c\n"
     ]
    }
   ],
   "source": [
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment.get(workspace=ws, name=\"AzureML-Minimal\")\n",
    "\n",
    "experiment_name = \"Artifactory_train\"\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ScriptRunConfig(source_directory=\"\",\n",
    "                      script='train.py',\n",
    "                      compute_target=\"local\",\n",
    "                      environment=myenv)\n",
    "\n",
    "# # Set compute target\n",
    "# # Skip this if you are running on your local computer\n",
    "# script_run_config.run_config.target = my_compute_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing hyperparameters as a dictionary, because we can directly log this config dict to W&B.\n",
    "CONFIG = dict(\n",
    "    # width of window\n",
    "    width = 512,\n",
    "    convolution_features=[256, 128, 64, 32],\n",
    "    convolution_width=[5, 9, 17, 33],\n",
    "    convolution_dropout=0.0,\n",
    "    transformer_heads=2,\n",
    "    transformer_feedforward=128,\n",
    "    transformer_layers=2,\n",
    "    transformer_dropout=0,\n",
    "    loss=\"mask\",\n",
    "    loss_boost_fp=0,\n",
    "    \n",
    "    artifact=Saw(min_width=4, max_width=32),\n",
    "    # Optimizer Parameter\n",
    "\n",
    "    # LearningRate Scheduler\n",
    "    \n",
    "    # parameters for study\n",
    "    batch_size = 32, # 'values': [32, 64, 128]\n",
    "    \n",
    "    wandb_group_name = \"test_setup\",\n",
    "    wandb_project_name = \"artifactory\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindowTransformerDetector_528.96K_19-12-2023_14:49:17\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = WindowTransformerDetector(window=CONFIG[\"width\"],                    \n",
    "                                  convolution_features=CONFIG[\"convolution_features\"],\n",
    "                                  convolution_width=CONFIG[\"convolution_width\"],\n",
    "                                  convolution_dropout=CONFIG[\"convolution_dropout\"],\n",
    "                                  transformer_heads=CONFIG[\"transformer_heads\"],\n",
    "                                  transformer_feedforward=CONFIG[\"transformer_feedforward\"],\n",
    "                                  transformer_layers=CONFIG[\"transformer_layers\"],\n",
    "                                  transformer_dropout=CONFIG[\"transformer_dropout\"],\n",
    "                                  loss=CONFIG[\"loss\"],\n",
    "                                  loss_boost_fp=CONFIG[\"loss_boost_fp\"])\n",
    "# model = ConvolutionDetector(convolution_features=[128, 64, 32],\n",
    "#                             convolution_width=[5, 9, 33],\n",
    "#                             convolution_dilation=[1, 1, 1],\n",
    "#                             convolution_dropout=0.0,\n",
    "#                             convolution_activation=\"sigmoid\")\n",
    "model_name = f\"{model.__class__.__name__}_{parameters_k(model)}_{datetime.now(pytz.timezone('Europe/Amsterdam')).strftime('%d-%m-%Y_%H:%M:%S')}\"\n",
    "CONFIG['wandb_run_name'] = model_name\n",
    "\n",
    "val_file = Path(f\"../data/validation{CONFIG['width']}.all.pkl\")\n",
    "val_datasets = [\n",
    "    #\"australian_electricity_demand_dataset\",\n",
    "    #\"electricity_hourly_dataset\",\n",
    "    #\"electricity_load_diagrams\",\n",
    "    #\"HouseholdPowerConsumption1\",\n",
    "    #\"HouseholdPowerConsumption2\",\n",
    "    #\"london_smart_meters_dataset_without_missing_values\",\n",
    "    \"solar_10_minutes_dataset\",\n",
    "    #\"wind_farms_minutely_dataset_without_missing_values\",\n",
    "]\n",
    "train_datasets = [\n",
    "    #\"australian_electricity_demand_dataset\",\n",
    "    #\"electricity_hourly_dataset\",\n",
    "    #\"electricity_load_diagrams\",\n",
    "    #\"HouseholdPowerConsumption1\",\n",
    "    #\"HouseholdPowerConsumption2\",\n",
    "    #\"london_smart_meters_dataset_without_missing_values\",\n",
    "    \"solar_10_minutes_dataset\",\n",
    "    #\"wind_farms_minutely_dataset_without_missing_values\",\n",
    "]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series(names: list[str], split: str):\n",
    "    series = list()\n",
    "    counts = list()\n",
    "    for name in names:\n",
    "        with open(f\"../data/processed/{name}_{split}.pickle\", \"rb\") as f:\n",
    "            raw = [a for a in pickle.load(f) if len(a) > CONFIG[\"width\"]]\n",
    "            series.extend(np.array(a).astype(np.float32) for a in raw)\n",
    "            counts.extend(repeat(1 / len(raw), len(raw)))\n",
    "    counts = np.array(counts)\n",
    "    return series, counts / counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_data, train_weights = load_series(train_datasets, \"TRAIN\")\n",
    "train_dataset = ArtifactDataset(train_data,\n",
    "                                width=CONFIG[\"width\"],\n",
    "                                padding=64,\n",
    "                                artifact=CONFIG[\"artifact\"],\n",
    "                                weight=train_weights) \n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "if not val_file.exists():\n",
    "    val_data, val_weights = load_series(val_datasets, \"TEST\")\n",
    "    val_gen = ArtifactDataset(val_data,\n",
    "                              width=CONFIG[\"width\"],\n",
    "                              padding=64,\n",
    "                              artifact=CONFIG[\"artifact\"],\n",
    "                              weight=val_weights)\n",
    "    val = CachedArtifactDataset.generate(val_gen,\n",
    "                                         n=2048,\n",
    "                                         to=val_file)\n",
    "else:\n",
    "    val = CachedArtifactDataset(file=val_file)\n",
    "val_loader = DataLoader(val, batch_size=CONFIG[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8020, 0.8006, 0.7920,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.6971, 0.7012, 0.7033],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.2615, 0.2385, 0.3421],\n",
       "        [0.0000, 0.0019, 0.0076,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.6250, 0.6420, 0.6534,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhvonhue\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/AICoE_Ramping_Artefacts/artifactory-master/notebooks/wandb/run-20231219_104644-6wk9menw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hvonhue/artifactory/runs/6wk9menw' target=\"_blank\">WindowTransformerDetector_528.96K_19-12-2023_11:45:52</a></strong> to <a href='https://wandb.ai/hvonhue/artifactory' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hvonhue/artifactory' target=\"_blank\">https://wandb.ai/hvonhue/artifactory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hvonhue/artifactory/runs/6wk9menw' target=\"_blank\">https://wandb.ai/hvonhue/artifactory/runs/6wk9menw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize W&B run\n",
    "run = wandb.init(project=CONFIG[\"wandb_project_name\"], \n",
    "        config=CONFIG,\n",
    "        entity=\"hvonhue\",\n",
    "        group=CONFIG[\"wandb_group_name\"], \n",
    "        job_type='train',\n",
    "        name=CONFIG[\"wandb_run_name\"])\n",
    "\n",
    "wandb.config.type = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhvonhue\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231219_134940-tytfi6nb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hvonhue/artifactory/runs/tytfi6nb' target=\"_blank\">WindowTransformerDetector_528.96K_19-12-2023_14:49:17</a></strong> to <a href='https://wandb.ai/hvonhue/artifactory' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hvonhue/artifactory' target=\"_blank\">https://wandb.ai/hvonhue/artifactory</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hvonhue/artifactory/runs/tytfi6nb' target=\"_blank\">https://wandb.ai/hvonhue/artifactory/runs/tytfi6nb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type                        | Params\n",
      "-------------------------------------------------------------\n",
      "0 | convolutions | Sequential                  | 503 K \n",
      "1 | position     | SinusoidalPositionEmbedding | 0     \n",
      "2 | dropout      | Dropout                     | 0     \n",
      "3 | transformer  | TransformerEncoder          | 25.4 K\n",
      "4 | linear       | Linear                      | 33    \n",
      "-------------------------------------------------------------\n",
      "528 K     Trainable params\n",
      "0         Non-trainable params\n",
      "528 K     Total params\n",
      "2.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 7000/? [1:21:12<00:00,  1.44it/s, v_num=i6nb]        "
     ]
    }
   ],
   "source": [
    "# initialize callbacks\n",
    "checkpointcallback = ModelCheckpoint(monitor=\"validation\",\n",
    "                                     mode=\"min\",\n",
    "                                     save_top_k=1)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# initialize logger\n",
    "logger = WandbLogger(project=\"artifactory\",\n",
    "                     name=model_name,\n",
    "                     log_model=\"all\")\n",
    "\n",
    "# initialize trainer\n",
    "trainer = Trainer(logger=logger,\n",
    "                  max_steps=50000,\n",
    "                  val_check_interval=1000,\n",
    "                  callbacks=[checkpointcallback,\n",
    "                             lr_monitor])\n",
    "\n",
    "# train\n",
    "trainer.fit(model,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End Wandb run\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
